1. What is the key difference between distributed and parallel systems?
2. What are the key problems with distributed systems?
3. What are logical clocks?
4. What are the differences between Lamport clocks and vector clocks?
5. How do we make decisions in distributed settings?
6. How does Paxos protocol work?
7. How does Raft protocol work?
8. What is Byzantine fault tolerance?
___
1. **paralel systems** use shared memory
	- *Distributed* Parallel systems still use the notion of shared memory, but this is coordinated with special HW/SW that unifies memory acces across multiple computers
![[Pasted image 20231104140922.png]]
	- **Distributed systems** use no shared components
![[Pasted image 20231104141219.png]]
2. Fallacies of distributed systems
	- [The network is reliable](https://aphyr.com/posts/288-the-network-is-reliable)
	- Latency is zero
	- Bandwidth is infinite
	- The network is secure
	- Topology does not change
	- Transport cost is zero
	- The network is homogeneous
	**Four main problems**
	- **Partial failures**: Some parts of the system might fail without clear reason, while other parts work fine
	- **Unreliable networks**: Communication between systems in over an unreliable network
	- **Unreliable time**: Time is a universal coordination principle. However, we cannot use time determine order. 
	- **No single source of truth, different opinions**: Distributed systems need to co-ordinate and agree upon a (version of ) truth
3. Logical time is a notion introduced by Lamport. 
	**Idea**: Instead of using the precise clock time, capture the events relationship between a pair of events. 
	Based on **causality**: if some event possibly causes another event, then the first event **happend-before** the other
4. Lamport clocks try to maintain order through 1 single value and trying to increment that while vector clocks try to achieve the same goal using a vector that saves the counter for every single node. 
	- **Lamport Clocks**: **Lamport clocks** can only provide a partial order of events. They ensure that causally related events are correctly ordered but may allow unrelated events to be ordered arbitrarily due to the lack of information about other processes' states. This can lead to a more relaxed and partial notion of concurrency.
	- **Vector Clocks**: **Vector clocks** provide a more accurate and consistent ordering of events. They can distinguish between concurrent events (events that are not causally related) and correctly order them. **Vector clocks** are able to capture causality relationships more precisely than **Lamport clocks**.
5. [the answer Decision making](5.%20Distributed%20systems#%20Distributed%20Decision%20Making)
6. [paxos protocol](5.%20Distributed%20systems##%20Paxos%20consensus%20algorithm)
7. [Raft consensus algorithm](5.%20Distributed%20systems##%20Raft%20consensus%20algorithm)
8. Raft and Paxos tolerate crash fault but not Byzantine faults: They assume that the exchanged messages are valid and true
	In open distributed systems (e.g. BitCoin) this assumption is not necessarily valid. Most open distributed systems use public-key cryptography and node registration before they start and sign messages to avoid MITM attacks.
	Still, decisions require majority votes, typically requires n>=3f+1 nodes where f is the number of faulty nodes.






# Partial Failures

![[Pasted image 20231104143305.png]]

“_A distributed system is one in which the failure of a computer you didn’t even know existed can render your own computer unusable_” (Leslie Lamport)

Distributed systems must tolerate partial failures: Any one point in the system can fail, yet the system must continue to correctly function as a whole.

Partial failures occur frequently in large distributed systems and they may cause [real-world outages](https://equalocean.com/news/201903031507).

Hard to detect whether something failed or not, as the time it takes for a message to travel across a network.
___
# Unreliable Networks
![[Pasted image 20231104143252.png]]
Unreliable networks
## Network failures
**Q**: Imagine a client server application. The client sends a message to the server, but receives no response. What might have gone wrong?

**A:** Has the service failed? Is the request or response message lost in the network?

The answer depends on the network assumptions.
## Asynchronous vs synchronous systems

Two types of network systems:

- **Synchronous system**: Process execution speeds or message delivery times are bounded. In a synchronous system, we can have:
    - Timed failure detection
    - Time based coordination
    - Worst-case performance
- **Asynchronous system**: No assumptions about process execution speeds or message delivery times are made.

Purely synchronous systems only exist in theory.

Most distributed systems use some form of asynchronous networking to communicate.
### Failures in asynchronous systems

Upon waiting for a response to a requests in an **asynchronous system**, it is **not possible to distinguish** whether:

1. the request was lost
2. the remote node is down
3. the response was lost

The usual remedy is to set _timeouts_ and retry the request until it succeeds.

Timeouts is a fundamental design choice in asynchronous networks: Ethernet, TCP and most application protocols work with timeouts.

The retransmission of the messages may help ensure the reliability of the communication links but introduce unpredictable delays. In this sense, practical systems are partially synchronous:

- **Partially-synchronous system**: There exist upper bounds on the network delay but the programmer does not know them.
___
# Unreliable Time
![[Pasted image 20231104143322.png]]
## Time is essential
In distributed systems, time is the only constant between nodes that can be relied upon to make distributed decisions on the ordering of problems. 
When do we need to order? 
- **Sequencing** items in memory
- Mutual **exclusion** of access to a shared resource
- **Encoding** history (“happens before” relationships)
- **Transactions** in a database
- **Consistency** of distributed data
- **Debugging** (finding the root cause of a bug)
## Time in computer systems
2 ways of keeping time: 
- "Real" time clocks (RTCs): - Capture our intuition about time and are kept in sync with the NTP protocol with centralised servers. (e.g. `System.getCurrentTimeMillis`).
- Monotonic clocks: Those clocks only move forward. 
## Time in centralised vs distributed systems
**Centralised systems**: system calls to kernel, monotonically increasing time values.
**Distributed systems**: Achieving agreement on time is not trivial!
## The trouble with computer clocks

Monotonic clocks are maintained by the OS and rely on HW counters exposed by CPUs. They are (usually!) good for determining order within a node, but each node only has its own notion of time.

NTP can synchronize time across nodes with an accuracy of _ms_. A modern CPU can execute 106 instructions (× number of cores) in an ms!

Moreover, _leap seconds_ are introduced every now and then; minutes may last for 61 or 59 seconds on occasion

μs accuracy is possible with GPS clocks, but expensive
## Logical time
### Happens-before relation
Events in the distributed system: 
- A process preforms some local computation
- A process sends a message
- A process receives a message
### Lamport timestamps
The eponymous logical timestamps
- Each individual process *p* maintains a counter: *LT(P)*
- When a process *p* performs an action, it increments *LT(P)*
- When a process *p* sends a message it includes *LT(p)* in the message
- When a process *p* receives a message from a process *q*, that message includes the value of *LT(q)*; *p* updates its *LT(p)* to the *max(LT(p),LT(q))+1*
## Vector clocks
On a system with *N* nodes, each node *i* maintains a vector *V_i* of size *N*. 
- $V_{i}[i]$ is the number of events that occurred at node *i*
- $V_{i}[j]$ is the number of events that occurred ate node *j*
They update as follows
- local events update $V_{i}[i]$
- When *i* sends a message to *j*, it includes $V_{i}$
- When *j* receives $V_{i}$, it updates all elements of $V_{j}$ to $V_{j}[a]=max(V_{i}[a], V_{j}[a])$

### Vector clocks guarantees
For two events a and b and their vector clocks VC(a) and VC(b):
- if a→b, then VC(a)<VC(b)
- if VC(a)<VC(b), then a→b

Vector clocks are [expensive](http://www.bailis.org/blog/causality-is-expensive-and-what-to-do-about-it/) to maintain: they require O(n) timestamps to be exchanged with each communication.

However, it has been shown that we cannot do better than vector clocks.

# Distributed Decision Making

## What is true in a distributed setting
Nodes cannot know anything for sure. Individual nodes cannot rely on their own information. Parts of the system know a different version of the truth than the other part(s)
## Consensus for distributed decision making
Consensus: Providing agreement in the presence of faulty nodes.
![[Pasted image 20231104161607.png]]
- Resource allocation
- Committing a transaction
- Synchronising state machines
- Leader election
- Atomic broadcasts
### The 2 generals problem
The two generals problem setting

- 2 armies camped in opposing hills (A1 and A2)
- The are only able to communicate with messengers
- They need to decide on a time to attack
- Enemy (B) is camped between the two hills and can at any time intercept the messengers

**Q** How can the generals decide when to attack?

**A** It is impossible to make a reliable decision.
### Approximate solutions
- Approximate solutions:
    - Pre-agree on timeouts
    - Send n labeled messages
    - Receiver calculates received messages within time window, then decides how many messages to send for ack.

Consequences: we can only make distributed decisions using either reliable communication or more than 2 parties.
## FPL impossibility
Fischer, Linch and Patterson theorem: _In an asynchronous network, consensus cannot be reached if at least one node fails in asynchronous networks_
A foundational result, proving the impossibility of distributed consensus. The system model the authors assume is fairly restrictive:

- Asynchronous communication
- No clocks or timeouts
- No random number generators

States that in an asynchronous system there is no algorithm _that solves consensus in every possible run_.

In practice however, we can mitigate the consequences, using randomisation and and partial synchrony. 
## The Byzantine generals problem
- Several divisions of the Byzantine army are cramped outside an enemy city, each division commanded by its own general
- They must decide upon a common plan
- generals communicate using messengers
- There might be traitors
- All loyal generals must agree on a plan

### Fault tolerant consensus
Fault tolerant consensus:
- PBFT - Byzantine fault tolerant consensus with at least **3f+1** nodes with **f** traitors
- Paxos , Raft  - Crash fault tolerant consensus with at least **2f+1** nodes with **f** faulty nodes
### Consensus protocols
A consensus protocol defines a set of rules for message exchange and processing for distributed components to reach agreement.

Basic properties of _crash fault-tolerant consensus protocols_ include:

- **Safety:** Never returning an incorrect result, in the presence of _non-_ Byzantine conditions.
- **Availability:** Able to provide an answer if n/2+1 servers are operational.
- **No clocks:** They do not depend on RTCs to work
- **Immune to stranglers:** If n/2+1 servers vote, then the result is considered safe.
## Paxos consensus algorithm
Three roles:
- **Proposer** Choose a value and sends it to a set of acceptors to collect votes. 
- **Acceptor**: Vote to accept or reject the values proposed by the proposer. For fault tolerance, the algorithm requires only a majority of the acceptor votes
- **Learner**: They adopt the value when a large enough number of acceptors have accepted it. 
Every proposal consists of a value, proposed by the client, and a unique monotonically increasing proposal number, aka _ballot_number.

Acceptance of the proposals by _a majority of processes/servers_ provide fault tolerance.
### Steps
**Phase 1: Voting**
- **(Prepare)** A proposer selects a proposal number n and sends a “prepare” request Prepare(n) to acceptors.
- **(Promise)** If _n_ is higher than every previous proposal number received, then the Acceptor returns “Promise”, to the Proposer, to ignore all future proposals having a number less than _n_. If the Acceptor accepted a proposal at some point in the past, it must include the previous proposal number, say _m_, and the corresponding accepted value, say _w_, in its response to the Proposer.

**Phase 2: Replication**
- **(Accept)** If the proposer receives a response from a majority of acceptors, then it sends an accept request for a proposal numbered _n_ with the highest-numbered proposal among the responses.  
- **(Accepted)** If an acceptor receives an accept request for a proposal numbered n, it accepts the proposal unless it has already responded to a prepare request having a number greater or equal than the proposal number.

## Raft consensus algorithm
Leader based asymmetric model: a node can only be in one of 3 states: Leader, Follower or Candidate
Separates **Leader election** and **Log replication** states:![[Pasted image 20231104170252.png]]
### Cluster states
Leader election
- Select one server to act as leader
- Detect crashes, choose new leader
Log replication (normal operation)
- Leader accepts commands from clients, appends to its log
- Leader replicates its log to other servers
Raft ensures: Logs are always consistent and only servers with up-to-date logs can become leader
### Taft leader election
Raft defines the following server states:
- **Candidate**: candidate for being a leader, asking for votes 
- **Leader**: Accepts log entries form clients, replicates them on other servers
- **Follower**: replicate the leader's state machine
Each server maintains current term value (no global view):

- Exchanged in every RPC
- Peer has later term? Update term, revert to follower

Raft selects at most one leader at each term. For some terms, the election may fail and result in no leader for that term.