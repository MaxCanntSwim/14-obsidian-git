1. What is a pipe(-line)?
2. Which `map`-like operations does Unix support?
3. Which `reduce`-like operations does Unix support?
4. How can we:
    - Find all files that contain a pattern?
    - Process data as they come?
    - Compare file contents?
    - Run commands in parallel?
___
1. the pipe operator `|` is used to combine commands
	- `cat file |wc -l`: Count lines of file
	- `find / -type d | sort`: View all directories sorted
	- `cat /var/log/access_log |grep foo|tail -n 10`: See the last 10 accesses from the host “foo” to our system’s web server.
	- `cat /etc/passwd |cut -f1 -d':'|sort`: Get a sorted list of the system’s users.
2. examples 
	- `tr` character translator; can convert or delete specific characters
		- `-s`: replace repeating characters into
		- `-d`: delete a character
	```bash
	echo "foo bar" | tr 'o' 'a'
	
	faa bar
	# Replace tabs with spaces
	tr '\t' ' ' < file.txt
	# Remove all instances of #
	tr -d '#' < file.txt
	```
	- `cut` allows us to split a line into columns, given a character, and extract specific fields.
	```bash
	# Get a list of users and home directories
	cut -f1,6 -d: /etc/passwd
	# Get details for all users that are running java
	ps -ef|tr -s ' '|grep "java"|cut -f3,11  -d' '
	```
	- `sed` Modify a string at its input in various ways using pattern matching
	```bash
	# Replace foo with bar in the input file
	sed -e 's/foo/bar/' < file.txt
	
	# Change the order of columns in a 2 column file
	sed -e 's/^\(.*\) \(.*\)$/\2 \1/' < file.txt
	
	# Remove lines 3 and 5 from the input
	sed -e '3d' -e '5d' < book.txt
	```
	- `sed` is a domain specific language of its own. You can find a thorough manual [here](https://www.computerhope.com/unix/used.htm)
3. there are multiple commands that can function like reduce
	- `awk`: The `awk` command is a versatile text processing tool that can be used to extract, transform, and summarise data from structured text files. It allows you to define custom processing rules and perform operations like summing, averaging, and more.
	```bash
		# Example: Summing values in the third column of a CSV file.
	    awk -F',' '{ sum += $3 } END { print sum }' data.csv
	```
	- `sort` and `uniq`: The `sort` command can be used to sort lines in a file, and `uniq` can eliminate duplicate lines. These two commands can be combined to perform operations like counting unique values or finding duplicates in a dataset.
	```bash
	    # Example: Counting the occurrences of each unique word in a text file.
	    cat words.txt | tr ' ' '\n' | sort | uniq -c
	```
	- `grep` and `sed`: The `grep` command searches for patterns in text, while `sed` can be used for text transformations. You can use these tools to filter and modify data, performing operations like finding lines containing specific text or replacing text.
	```bash
	    # Example: Extracting lines containing a specific keyword from a log file.
	    grep "error" logfile.txt
	```
	- `cut`: The `cut` command is used to extract specific columns or fields from lines of text. It can be helpful when you need to select certain parts of the data.
	```bash
	    # Example: Extracting the second and third columns from a CSV file.
	    cut -d',' -f2,3 data.csv
	```
	- `paste`: The `paste` command can be used to combine lines from multiple files side by side, which can be thought of as a simple "merge" or "join" operation.
	```bash
	    # Example: Merging lines from two text files
	     paste file1.txt file2.txt
	```
	- `xargs`: The `xargs` command reads items from standard input and executes a command with those items as arguments. It can be used for operations like applying a command to a list of files.
	```bash
	    # Example: Deleting multiple files that match a pattern.
	    ls *.log | xargs rm
	```
4. 